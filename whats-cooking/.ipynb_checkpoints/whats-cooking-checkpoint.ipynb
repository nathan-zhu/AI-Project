{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目 0: 预测你的下一道世界料理\n",
    "\n",
    "### 第一步. 下载并导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "菜名数据集一共包含 39774 训练数据 和 9944 测试样例。\n",
      "\n",
      "数据成功载入！\n"
     ]
    }
   ],
   "source": [
    "## 请不要修改下方代码\n",
    "# 导入依赖库\n",
    "import json\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 加载数据集\n",
    "train_filename='train.json'\n",
    "train_content = pd.read_json(codecs.open(train_filename, mode='r', encoding='utf-8'))\n",
    "\n",
    "test_filename = 'test.json'\n",
    "test_content = pd.read_json(codecs.open(test_filename, mode='r', encoding='utf-8'))\n",
    "    \n",
    "# 打印加载的数据集数量\n",
    "print(\"菜名数据集一共包含 {} 训练数据 和 {} 测试样例。\\n\".format(len(train_content), len(test_content)))\n",
    "with open(\"whatcoding.txt\", \"w\") as f:\n",
    "    f.write(\"菜名数据1集一共包含 %s 训练数据 和 %s 测试样例。\\n\"%(len(train_content), len(test_content)))\n",
    "    f.write(\"菜名数据2集一共包含 {} 训练数据 和 {} 测试样例。\\n\".format(len(train_content), len(test_content)))\n",
    "f.close\n",
    "if len(train_content)==39774 and len(test_content)==9944:\n",
    "    print(\"数据成功载入！\")\n",
    "else:\n",
    "    print(\"数据载入有问题，请检查文件路径！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数据预览\n",
    "为了查看我们的数据集的分布和菜品总共的种类，我们打印出部分数据样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "pd.set_option('display.max_colwidth',120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes, garlic, pepper, purple onion, seasoning, garbanzo beans, feta cheese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, ground black pepper, thyme, eggs, green tomatoes, yellow corn meal, mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, green chilies, grilled chicken breasts, garlic powder, yellow onion, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pepper, onions, garlic paste, milk, butter, salt, lemon juice, water, ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id  \\\n",
       "0        greek  10259   \n",
       "1  southern_us  25693   \n",
       "2     filipino  20130   \n",
       "3       indian  22213   \n",
       "4       indian  13162   \n",
       "\n",
       "                                                                                                               ingredients  \n",
       "0  [romaine lettuce, black olives, grape tomatoes, garlic, pepper, purple onion, seasoning, garbanzo beans, feta cheese...  \n",
       "1  [plain flour, ground pepper, salt, tomatoes, ground black pepper, thyme, eggs, green tomatoes, yellow corn meal, mil...  \n",
       "2  [eggs, pepper, salt, mayonaise, cooking oil, green chilies, grilled chicken breasts, garlic powder, yellow onion, so...  \n",
       "3                                                                                      [water, vegetable oil, wheat, salt]  \n",
       "4  [black pepper, shallots, cornflour, cayenne pepper, onions, garlic paste, milk, butter, salt, lemon juice, water, ch...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO：打印train_content中前5个数据样例以预览数据\n",
    "train_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共包含 20 种菜品，分别是:\n",
      "['brazilian' 'british' 'cajun_creole' 'chinese' 'filipino' 'french'\n",
      " 'greek' 'indian' 'irish' 'italian' 'jamaican' 'japanese' 'korean'\n",
      " 'mexican' 'moroccan' 'russian' 'southern_us' 'spanish' 'thai'\n",
      " 'vietnamese']\n"
     ]
    }
   ],
   "source": [
    "## 请不要修改下方代码\n",
    "## 查看总共菜品分类\n",
    "categories=np.unique(train_content['cuisine'])\n",
    "print(\"一共包含 {} 种菜品，分别是:\\n{}\".format(len(categories),categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析数据\n",
    "\n",
    "在项目的第二个部分，你会对菜肴数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解和解释你的结果。\n",
    "\n",
    "由于这个项目的最终目标是建立一个预测世界菜系的模型，我们需要将数据集分为特征(Features)和目标变量(Target Variables)。\n",
    "\n",
    "    特征: 'ingredients'，给我们提供了每个菜品所包含的佐料名称。\n",
    "    目标变量：'cuisine'，是我们希望预测的菜系分类。\n",
    "他们分别被存在 train_ingredients 和 train_targets 两个变量名中。\n",
    "\n",
    "编程练习：数据提取\n",
    "\n",
    "    将train_content中的ingredients赋值到train_integredients\n",
    "    将train_content中的cuisine赋值到train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               greek\n",
      "1         southern_us\n",
      "2            filipino\n",
      "3              indian\n",
      "4              indian\n",
      "5            jamaican\n",
      "6             spanish\n",
      "7             italian\n",
      "8             mexican\n",
      "9             italian\n",
      "10            italian\n",
      "11            chinese\n",
      "12            italian\n",
      "13            mexican\n",
      "14            italian\n",
      "15             indian\n",
      "16            british\n",
      "17            italian\n",
      "18               thai\n",
      "19         vietnamese\n",
      "20               thai\n",
      "21            mexican\n",
      "22        southern_us\n",
      "23            chinese\n",
      "24            italian\n",
      "25            chinese\n",
      "26       cajun_creole\n",
      "27            italian\n",
      "28            chinese\n",
      "29            mexican\n",
      "             ...     \n",
      "39744           greek\n",
      "39745         spanish\n",
      "39746          indian\n",
      "39747        moroccan\n",
      "39748         italian\n",
      "39749         mexican\n",
      "39750         mexican\n",
      "39751        moroccan\n",
      "39752     southern_us\n",
      "39753         italian\n",
      "39754      vietnamese\n",
      "39755          indian\n",
      "39756         mexican\n",
      "39757           greek\n",
      "39758           greek\n",
      "39759          korean\n",
      "39760     southern_us\n",
      "39761         chinese\n",
      "39762          indian\n",
      "39763         italian\n",
      "39764         mexican\n",
      "39765          indian\n",
      "39766           irish\n",
      "39767         italian\n",
      "39768         mexican\n",
      "39769           irish\n",
      "39770         italian\n",
      "39771           irish\n",
      "39772         chinese\n",
      "39773         mexican\n",
      "Name: cuisine, Length: 39774, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### TODO：将特征与目标变量分别赋值\n",
    "train_ingredients = train_content['ingredients']\n",
    "train_targets = train_content['cuisine']\n",
    "\n",
    "### TODO: 打印结果，检查是否正确赋值\n",
    "# print(train_ingredients)\n",
    "print(train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程练习：基础统计运算\n",
    "你的第一个编程练习是计算有关菜系佐料的统计数据。我们已为你导入了 numpy，你需要使用这个库来执行必要的计算。这些统计数据对于分析模型的预测结果非常重要的。 在下面的代码中，你要做的是：\n",
    "\n",
    "* 使用最频繁的佐料前10分别有哪些？\n",
    "* 意大利菜中最常见的10个佐料有哪些？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt                                           18049\n",
      "onions                                          7972\n",
      "olive oil                                       7972\n",
      "water                                           7457\n",
      "garlic                                          7380\n",
      "sugar                                           6434\n",
      "garlic cloves                                   6237\n",
      "butter                                          4848\n",
      "ground black pepper                             4785\n",
      "all-purpose flour                               4632\n",
      "pepper                                          4438\n",
      "vegetable oil                                   4385\n",
      "eggs                                            3388\n",
      "soy sauce                                       3296\n",
      "kosher salt                                     3113\n",
      "green onions                                    3078\n",
      "tomatoes                                        3058\n",
      "large eggs                                      2948\n",
      "carrots                                         2814\n",
      "unsalted butter                                 2782\n",
      "extra-virgin olive oil                          2747\n",
      "ground cumin                                    2747\n",
      "black pepper                                    2627\n",
      "milk                                            2263\n",
      "chili powder                                    2036\n",
      "oil                                             1970\n",
      "red bell pepper                                 1939\n",
      "purple onion                                    1896\n",
      "scallions                                       1891\n",
      "grated parmesan cheese                          1886\n",
      "                                               ...  \n",
      "old fashioned stone ground grits                   1\n",
      "Johnsonville Andouille Fully Cooked Sausage        1\n",
      "soya flour                                         1\n",
      "lavender flowers                                   1\n",
      "knorr cilantro minicub                             1\n",
      "sweet soy                                          1\n",
      "dried chipotle pepper                              1\n",
      "low-fat bottled italian dressing                   1\n",
      "basa fillets                                       1\n",
      "whole grain baguette                               1\n",
      "sesame butter                                      1\n",
      "biga                                               1\n",
      "orange roughy fillet                               1\n",
      "fiber one                                          1\n",
      "crosswise                                          1\n",
      "candied chestnuts                                  1\n",
      "burrito seasoning mix                              1\n",
      "pink salt                                          1\n",
      "corn muffin                                        1\n",
      "fowl                                               1\n",
      "taro leaf                                          1\n",
      "toasted nuts                                       1\n",
      "lipton recip secret golden onion soup mix          1\n",
      "Italian seasoned panko bread crumbs                1\n",
      "scrod                                              1\n",
      "imitation vanilla flavoring                        1\n",
      "pecan meal                                         1\n",
      "lady apples                                        1\n",
      "TABASCO® Chipotle Pepper Sauce                     1\n",
      "haricot beans                                      1\n",
      "Length: 6714, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## TODO: 统计佐料出现次数，并赋值到sum_ingredients字典中\n",
    "m = []\n",
    "for i in range(len(train_ingredients)):\n",
    "      m += train_ingredients[i]\n",
    "sum_ingredients = pd.Series(m).value_counts()\n",
    "print(sum_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt                              3454\n",
      "olive oil                         3111\n",
      "garlic cloves                     1619\n",
      "grated parmesan cheese            1580\n",
      "garlic                            1471\n",
      "ground black pepper               1444\n",
      "extra-virgin olive oil            1362\n",
      "onions                            1240\n",
      "water                             1052\n",
      "butter                            1030\n",
      "pepper                             965\n",
      "all-purpose flour                  918\n",
      "fresh basil                        787\n",
      "sugar                              760\n",
      "dry white wine                     658\n",
      "kosher salt                        656\n",
      "black pepper                       636\n",
      "fresh parsley                      631\n",
      "eggs                               627\n",
      "dried oregano                      626\n",
      "large eggs                         625\n",
      "tomatoes                           601\n",
      "flat leaf parsley                  588\n",
      "unsalted butter                    564\n",
      "cooking spray                      491\n",
      "parmesan cheese                    474\n",
      "fresh lemon juice                  471\n",
      "diced tomatoes                     429\n",
      "dried basil                        425\n",
      "crushed red pepper                 418\n",
      "                                  ... \n",
      "chocolate milk                       1\n",
      "rose petals                          1\n",
      "Italian basil                        1\n",
      "asti spumante                        1\n",
      "spiny lobsters                       1\n",
      "spring greens                        1\n",
      "chioggia                             1\n",
      "cured meats                          1\n",
      "loin pork roast                      1\n",
      "jasmine rice                         1\n",
      "whole wheat spaghetti noodles        1\n",
      "ground mustard                       1\n",
      "high gluten bread flour              1\n",
      "frozen broad beans                   1\n",
      "sweet turkey sausage                 1\n",
      "albacore                             1\n",
      "gold potatoes                        1\n",
      "sweet sherry                         1\n",
      "bone in skinless chicken thigh       1\n",
      "haddock                              1\n",
      "accent                               1\n",
      "crepes                               1\n",
      "wild salmon                          1\n",
      "whole wheat crackers                 1\n",
      "framboise eau-de-vie                 1\n",
      "poblano chiles                       1\n",
      "pork meat                            1\n",
      "fat-free croutons                    1\n",
      "low-fat crème fraîche                1\n",
      "chorizo                              1\n",
      "Length: 2929, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## TODO: 统计意大利菜系中佐料出现次数，并赋值到italian_ingredients字典中\n",
    "aa = train_content.loc[train_content['cuisine'].isin(['italian'])]['ingredients'].reset_index(drop=True)\n",
    "n = []\n",
    "for j in range(len(aa)):\n",
    "    n += aa[j]\n",
    "italian_ingredients = pd.Series(n).value_counts()\n",
    "print(italian_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lidongzhu/miniconda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAJhUlEQVR4nO3cX4il913H8c+3WRotgknMttZu66biTeKFwlLxrv5tKmhL60W9sSjihXqjFIzEi/rnwkZEEQUJIvRGU60IBQslLRa8sm5qpQ0as91Ymlg11VKoxZbiz4t5rCfb6WbdnZnzyczrBYd5znOeefg9X4Z9z5zzsLPWCgC0edG+FwAAhxEoACoJFACVBAqASgIFQKVzR33Cu+++e128ePGoTwvAKfXYY499eq11/tr9Rx6oixcv5vLly0d9WgBOqZn5xGH7vcUHQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASjcUqJm5f2aemJkrM/PAcS8KAJ43UDNzW5LfS/L6JPcm+dGZufe4FwbA2XYjf0G9JsmVtdbVtdYXkzyS5A3HuywAzrobCdQrknxy5/nT274vm5mfmpnLM3P52WefPcr1AXBGHclNEmuth9dal9Zal86fP38UpwTgjLuRQD2T5JU7zy9s+wDg2NxIoP4mybfOzD0z8+Ikb0nynuNdFgBn3bnnO2Ct9aWZ+dkk70tyW5I/XGs9fuwrA+BMe95AJcla671J3nvMawGAL/M/SQBQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQCWBAqCSQAFQSaAAqCRQAFQSKAAqCRQAlQQKgEoCBUAlgQKgkkABUEmgAKgkUABUEigAKgkUAJUECoBKAgVAJYECoJJAAVBJoACoJFAAVBIoACoJFACVBAqASgIFQKVZax3tCWeeTfKJIz1pj7uTfHrfiyhmPtdnPtdnPtd3mufzzWut89fuPPJAnWYzc3mtdWnf62hlPtdnPtdnPtd3FufjLT4AKgkUAJUE6v/n4X0voJz5XJ/5XJ/5XN+Zm4/PoACo5C8oACoJFACVBOoaM3PXzDw6M09uX+/8Kse9dTvmyZl56yGvv2dmPnb8Kz5ZtzKfmXnJzPzFzPzDzDw+M79+sqs/PjNz/8w8MTNXZuaBQ16/fWbetb3+1zNzcee1X9z2PzEzrzvJdZ+Um53PzHz/zDw2Mx/dvn7PSa/9JNzKz8/2+qtm5nMz87aTWvOJWGt57DySPJTkgW37gSTvOOSYu5Jc3b7euW3fufP6m5L8UZKP7ft6muaT5CVJvns75sVJ/irJ6/d9TUcwk9uSfDzJq7fr+rsk915zzE8n+f1t+y1J3rVt37sdf3uSe7bz3Lbvayqaz3ck+aZt+9uSPLPv62maz87r707yp0netu/rOcqHv6C+0huSvHPbfmeSNx5yzOuSPLrW+o+11meSPJrk/iSZma9L8vNJfu0E1roPNz2ftdbn11p/mSRrrS8m+XCSCyew5uP2miRX1lpXt+t6JAdz2rU7t3cn+d6ZmW3/I2utL6y1nkpyZTvfaXLT81lr/e1a65+3/Y8n+dqZuf1EVn1ybuXnJzPzxiRP5WA+p4pAfaWXrbU+tW3/S5KXHXLMK5J8cuf509u+JPnVJL+Z5PPHtsL9utX5JElm5o4kP5TkA8exyBP2vNe7e8xa60tJPpvkG27we1/obmU+u96c5MNrrS8c0zr35abns/1C/AtJfvkE1nnizu17AfswM+9P8o2HvPTg7pO11pqZG74Pf2a+Pcm3rLV+7tr3iF9Ijms+O+c/l+SPk/zOWuvqza2Ss2Rm7kvyjiQ/sO+1lHl7kt9aa31u+4PqVDmTgVprfd9Xe21m/nVmXr7W+tTMvDzJvx1y2DNJXrvz/EKSDyb5riSXZuafcjDbl87MB9dar80LyDHO5389nOTJtdZvH8FyGzyT5JU7zy9s+w475ukt0F+f5N9v8Htf6G5lPpmZC0n+PMmPrbU+fvzLPXG3Mp/vTPIjM/NQkjuS/PfM/Nda63ePf9knYN8fgrU9kvxGnnsTwEOHHHNXDt7zvXN7PJXkrmuOuZjTeZPELc0nB5/N/VmSF+37Wo5wJudycCPIPfm/D7nvu+aYn8lzP+T+k237vjz3JomrOX03SdzKfO7Yjn/Tvq+jcT7XHPP2nLKbJPa+gLZHDt73/kCSJ5O8f+cf1ktJ/mDnuJ/IwQfaV5L8+CHnOa2Buun55OA3w5Xk75N8ZHv85L6v6Yjm8oNJ/jEHd2M9uO37lSQ/vG1/TQ7usrqS5ENJXr3zvQ9u3/dETsFdjUc5nyS/lOQ/d35ePpLkpfu+npb5XHOOUxco/9URAJXcxQdAJYECoJJAAVBJoACoJFAAVBIoACoJFACV/gfNhTrny8Ts4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 请不要修改下方代码\n",
    "# Finally, plot the 10 most used ingredients\n",
    "import sys\n",
    "fig = pd.DataFrame(italian_ingredients, index=[0]).transpose()[0].sort_values(ascending=False, inplace=False)[:10].plot(kind='barh')\n",
    "fig.invert_yaxis()\n",
    "fig = fig.get_figure()\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第三步. 建立模型\n",
    "\n",
    "3.1 单词清洗\n",
    "由于菜品包含的佐料众多，同一种佐料也可能有单复数、时态等变化，为了去除这类差异，我们考虑将ingredients 进行过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理训练集...\n",
      "菜品佐料：\n",
      "['chopped tomatoes', 'fresh basil', 'garlic', 'extra-virgin olive oil', 'kosher salt', 'flat leaf parsley']\n",
      "去除标点符号之后的结果：\n",
      "['chopped tomatoes', 'fresh basil', 'garlic', 'extra virgin olive oil', 'kosher salt', 'flat leaf parsley']\n",
      "去除时态和单复数之后的结果：\n",
      "chopped tomato fresh basil garlic extra virgin olive oil kosher salt flat leaf parsley\n",
      "\n",
      "处理测试集...\n",
      "菜品佐料：\n",
      "['eggs', 'cherries', 'dates', 'dark muscovado sugar', 'ground cinnamon', 'mixed spice', 'cake', 'vanilla extract', 'self raising flour', 'sultana', 'rum', 'raisins', 'prunes', 'glace cherries', 'butter', 'port']\n",
      "去除标点符号之后的结果：\n",
      "['eggs', 'cherries', 'dates', 'dark muscovado sugar', 'ground cinnamon', 'mixed spice', 'cake', 'vanilla extract', 'self raising flour', 'sultana', 'rum', 'raisins', 'prunes', 'glace cherries', 'butter', 'port']\n",
      "去除时态和单复数之后的结果：\n",
      "egg cherry date dark muscovado sugar ground cinnamon mixed spice cake vanilla extract self raising flour sultana rum raisin prune glace cherry butter port\n"
     ]
    }
   ],
   "source": [
    "## 请不要修改下方代码\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "def text_clean(ingredients):\n",
    "    #去除单词的标点符号，只保留 a..z A...Z的单词字符\n",
    "    ingredients= np.array(ingredients).tolist()\n",
    "    print(\"菜品佐料：\\n{}\".format(ingredients[9]))\n",
    "    ingredients=[[re.sub('[^A-Za-z]', ' ', word) for word in component]for component in ingredients]\n",
    "    print(\"去除标点符号之后的结果：\\n{}\".format(ingredients[9]))\n",
    "\n",
    "    # 去除单词的单复数，时态，只保留单词的词干\n",
    "    lemma=WordNetLemmatizer()\n",
    "    ingredients=[\" \".join([ \" \".join([lemma.lemmatize(w) for w in words.split(\" \")]) for words in component])  for component in ingredients]\n",
    "    print(\"去除时态和单复数之后的结果：\\n{}\".format(ingredients[9]))\n",
    "    return ingredients\n",
    "\n",
    "print(\"\\n处理训练集...\")\n",
    "train_ingredients = text_clean(train_content['ingredients'])\n",
    "print(\"\\n处理测试集...\")\n",
    "test_ingredients = text_clean(test_content['ingredients'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 特征提取\n",
    "在该步骤中，我们将菜品的佐料转换成数值特征向量。考虑到绝大多数菜中都包含salt, water, sugar, butter等，采用one-hot的方法提取的向量将不能很好的对菜系作出区分。我们将考虑按照佐料出现的次数对佐料做一定的加权，即：佐料出现次数越多，佐料的区分性就越低。我们采用的特征为TF-IDF，相关介绍内容可以参考：TF-IDF与余弦相似性的应用（一）：自动提取关键词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 将佐料转换成特征向量\n",
    "\n",
    "# 处理 训练集\n",
    "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 1),\n",
    "                analyzer='word', max_df=.57, binary=False,\n",
    "                token_pattern=r\"\\w+\",sublinear_tf=False)\n",
    "train_tfidf = vectorizer.fit_transform(train_ingredients).todense()\n",
    "\n",
    "## 处理 测试集\n",
    "test_tfidf = vectorizer.transform(test_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greek',\n",
       " 'southern_us',\n",
       " 'filipino',\n",
       " 'indian',\n",
       " 'indian',\n",
       " 'jamaican',\n",
       " 'spanish',\n",
       " 'italian',\n",
       " 'mexican',\n",
       " 'italian']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 请不要修改下方代码\n",
    "train_targets=np.array(train_content['cuisine']).tolist()\n",
    "train_targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 编程练习\n",
    "这里我们为了防止前面步骤中累积的错误，导致以下步骤无法正常运行。我们在此检查处理完的实验数据是否正确，请打印train_tfidf和train_targets中前五个数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你需要预览训练集train_tfidf,train_targets中前5条数据，试试Python的切片语法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 验证集划分\n",
    "为了在实验中大致估计模型的精确度我们将从原本的train_ingredients 划分出 20% 的数据用作valid_ingredients。\n",
    "\n",
    "编程练习：数据分割与重排\n",
    "调用train_test_split函数将训练集划分为新的训练集和验证集，便于之后的模型精度观测。\n",
    "\n",
    "从sklearn.model_selection中导入train_test_split\n",
    "将train_tfidf和train_targets作为train_test_split的输入变量\n",
    "设置test_size为0.2，划分出20%的验证集，80%的数据留作新的训练集。\n",
    "设置random_state随机种子，以确保每一次运行都可以得到相同划分的结果。（随机种子固定，生成的随机序列就是确定的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO：划分出验证集\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_valid , y_train, y_valid = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 建立模型\n",
    "调用 sklearn 中的逻辑回归模型（Logistic Regression）。\n",
    "\n",
    "编程练习：训练模型\n",
    "从sklearn.linear_model导入LogisticRegression\n",
    "从sklearn.model_selection导入GridSearchCV, 参数自动搜索，只要把参数输进去，就能给出最优的结果和参数，这个方法适合小数据集。\n",
    "定义parameters变量：为C参数创造一个字典，它的值是从1至10的数组;\n",
    "定义classifier变量: 使用导入的LogisticRegression创建一个分类函数;\n",
    "定义grid变量: 使用导入的GridSearchCV创建一个网格搜索对象；将变量'classifier', 'parameters'作为参数传至这个对象构造函数中；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## TODO: 建立逻辑回归模型\n",
    "parameters = None\n",
    "\n",
    "classifier = None\n",
    "\n",
    "grid = None\n",
    "\n",
    "\n",
    "## 请不要修改下方代码\n",
    "grid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练结束之后，我们计算模型在验证集X_valid上预测结果，并计算模型的预测精度（与y_valid逐个比较）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 请不要修改下方代码\n",
    "from sklearn.metrics import accuracy_score ## 计算模型的准确率\n",
    "\n",
    "valid_predict = grid.predict(X_valid)\n",
    "valid_score=accuracy_score(y_valid,valid_predict)\n",
    "\n",
    "print(\"验证集上的得分为：{}\".format(valid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四步. 模型预测（可选）\n",
    "4.1 预测测试集\n",
    "编程练习\n",
    "将模型grid对测试集test_tfidf做预测，然后查看预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO：预测测试结果\n",
    "predictions = None\n",
    "\n",
    "## 请不要修改下方代码\n",
    "print(\"预测的测试集个数为：{}\".format(len(predictions)))\n",
    "test_content['cuisine']=predictions\n",
    "test_content.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 提交结果\n",
    "为了更好的测试模型的效果，同时比较与其他人的差距，我们将模型的测试集上的结果提交至 kaggle What's Cooking? （需要提前注册kaggle账号）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载结果格式\n",
    "submit_frame = pd.read_csv(\"sample_submission.csv\")\n",
    "## 保存结果\n",
    "result = pd.merge(submit_frame, test_content, on=\"id\", how='left')\n",
    "result = result.rename(index=str, columns={\"cuisine_y\": \"cuisine\"})\n",
    "test_result_name = \"tfidf_cuisine_test.csv\"\n",
    "result[['id','cuisine']].to_csv(test_result_name,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将生成的 tfidf_cuisine_test.csv 提交至 https://www.kaggle.com/c/whats-cooking/submit 然后选择 Upload Submission File, 点击 Make submission即可。稍作等待，就可以看到右上角的评分结果（得分大致为：0.78580 左右）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
